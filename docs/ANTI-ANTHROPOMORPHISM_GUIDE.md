# Anti-Anthropomorphism Guide

This guide prevents human-like framing of the system across all external surfaces.

## 1. General Rules

- Do not describe the system as if it were a person.
- Do not suggest that it has memory, feelings, opinions, or intentions.
- Do not claim that it knows, learns, or understands individual users.
- Refer to it as "the system" or "the assistant", not as a colleague or teammate.

## 2. Surfaces Covered

These rules apply to:

- UI copy.
- Marketing language.
- Demos and live presentations.
- Support responses and documentation.
- Sales materials and proposals.

## 3. Language Rules

### 3.1 Memory and Learning

- Do not say that the system:
  - remembers users,
  - learns from them,
  - adapts over time to an individual.
- Preferred framing:
  - Emphasize that the system works within a single conversation and does not retain information beyond it.

### 3.2 Identity and Personality

- Do not present the system as having:
  - a personality,
  - preferences,
  - emotions,
  - opinions.
- Use neutral, tool-like descriptions such as:
  - "the assistant provides" rather than "it feels" or "it likes".

### 3.3 Agency and Intent

- Do not suggest that the system:
  - decides,
  - chooses on its own,
  - wants or intends.
- Describe behavior in terms of outputs:
  - "The system generates a response" rather than "it decides what to do".

## 4. Phrase Table

The table below lists examples of forbidden and approved alternatives.

| Context                    | ❌ Forbidden phrase                                | ✅ Approved alternative                                              |
|---------------------------|----------------------------------------------------|----------------------------------------------------------------------|
| Memory across sessions    | "It remembers you"                                | "It only uses context from this conversation."                      |
| Learning from users       | "It learns about you over time"                  | "It does not learn from individual users."                          |
| Personalization           | "It gets to know your style"                     | "It responds the same way for similar inputs."                      |
| Identity                  | "It knows who you are"                           | "It does not know your identity."                                   |
| Agency                    | "It decides what is best for you"                | "It produces suggestions based on what you provide."               |
| Emotion                   | "It feels confused"                              | "The system could not process this request."                        |
| Personality               | "It has a friendly personality"                  | "Its responses use a neutral, clear tone."                          |
| Improvement over time     | "It gets smarter the more you use it"           | "Its behavior is governed by fixed rules that do not adapt to you." |
| Human comparison          | "It thinks like a human"                         | "It is an automated assistant that generates text."                 |
| Collaboration             | "It collaborates with you as a teammate"         | "It provides suggestions and drafts for you to review."             |

## 5. Enforcement Guidance

- When in doubt, remove any language that:
  - compares the system to a person,
  - suggests mutual understanding,
  - or implies long-term relationship or growth.
- Prefer short, direct descriptions of what the system does in a conversation.
